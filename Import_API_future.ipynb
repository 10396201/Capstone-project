{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from blablacarapi import BlaBlaCarApi\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize API\n",
    "api = BlaBlaCarApi(api_key=\"e359fe6292be4078ba1dcc963577813f\", locale = 'it_IT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scraping(url):\n",
    "    RE_PUB_DATE = re.compile(r'.* (\\d+\\/\\d+\\/\\d+)')\n",
    "    RE_VIEWS = re.compile(r'.* (\\d+) .*')\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    #print soup.prettify()\n",
    "    info = soup.find('div', attrs={'class': 'RideDetails-publicationInfo u-table'}).text #Find (at most) *one*\n",
    "    info = info.replace('\\n','').replace('\\t','').split('-')\n",
    "    pub_date_str = info[0].strip()\n",
    "    pub_date = RE_PUB_DATE.match(pub_date_str).groups()[0]\n",
    "    views_str = info[1].strip()\n",
    "\n",
    "    pub_date = datetime.strptime(pub_date, \"%d/%m/%Y\").date()  # .date() because we just need the day and not also the time\n",
    "                                                                # this is the same format as depdate\n",
    "    views = int(RE_VIEWS.match(views_str).groups()[0])\n",
    "    return pub_date, views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_API(year,month,day_begin,day_end):\n",
    "    yearmonth = str(year)+'-'+str(month).zfill(2)+'-'\n",
    "    trip_data = []\n",
    "    for day in xrange(day_begin, day_end+1):\n",
    "        page = 1\n",
    "        date_query = yearmonth + str(day).zfill(2)\n",
    "        trips = api.trips(frm=\"Milano\", locale='it_IT', limit=100, db = date_query, de = date_query)\n",
    "        for t in trips.trips:\n",
    "            trip_data.append(extract_data(t))\n",
    "            \n",
    "            while trips.pager.has_next():\n",
    "                page += 1\n",
    "                trips = api.trips(frm=\"Milano\", page = page, locale='it_IT', limit=100, db = date_query, de = date_query)\n",
    "                for t in trips.trips:\n",
    "                    trip_data.append(extract_data(t))\n",
    "    \n",
    "    return tuplelist_to_df(trip_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_data(trip):\n",
    "    depdate = trip.departure_date\n",
    "    depplace = trip.departure_place\n",
    "    arrplace = trip.arrival_place\n",
    "    \n",
    "    link = trip.links['_front']    # link to the page of the trip (available only for trips \"in the future\")\n",
    "    pub_date, views = scraping(link)\n",
    "    \n",
    "    dep_day = depdate.date()       # date of the trip\n",
    "    dep_time = depdate.time()      # hour of departure\n",
    "    dep_city = depplace['city_name']  # city of dep\n",
    "    dep_lat = depplace['latitude']    # latitude of dep place\n",
    "    dep_long = depplace['longitude']  # longitude of dep place\n",
    "    dep_addr = depplace['address']    # address of dep place\n",
    "    arr_city = arrplace['city_name']  \n",
    "    arr_lat = arrplace['latitude']\n",
    "    arr_long = arrplace['longitude']\n",
    "    arr_addr = arrplace['address']\n",
    "    price = trip.price_with_commission['value'] # price with commission\n",
    "    seatsleft = trip.seats_left                 # seats left \n",
    "    seats = trip.seats                          # seats made available by the driver\n",
    "    trip_id = trip.permanent_id                 # trip id\n",
    "    stops = trip.locations_to_display           # locations in which the driver will stop\n",
    "    bookmode = trip.booking_mode                # could be MANUAL if the driver has to accept your request, AUTO otherwise\n",
    "    booktype = trip.booking_type                # payment method: ONLINE, ON BOARD\n",
    "    \n",
    "    return (link, dep_day, dep_time, dep_city, dep_lat, dep_long, dep_addr, arr_city, arr_lat, arr_long, arr_addr, price, \n",
    "         seatsleft, seats, trip_id, stops, bookmode, booktype, pub_date, views, date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tuplelist_to_df(L):\n",
    "    labels = ['link', 'dep_day', 'dep_time', 'dep_city', 'dep_lat', 'dep_long', 'dep_addr', 'arr_city', 'arr_lat', 'arr_long', \n",
    "              'arr_addr', 'price', 'seatsleft', 'seats', 'trip_id', 'stops', 'bookmode', 'booktype','pub_date','views','today']\n",
    "    df = pd.DataFrame.from_records(L, columns = labels)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python2.7/site-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "626\n"
     ]
    }
   ],
   "source": [
    "df_mar = get_data_API(2017,3,30,31)\n",
    "print len(df_mar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_mar.to_csv('./Data/Future/March2017.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267\n"
     ]
    }
   ],
   "source": [
    "df_apr = get_data_API(2017,4,1,30)\n",
    "print len(df_apr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_apr.to_csv('./Data/Future/April2017.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df_may = get_data_API(2017,5,1,31)\n",
    "print len(df_may)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_may.to_csv('./Data/Future/May2017.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df_jun = get_data_API(2017,6,1,30)\n",
    "print len(df_jun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_jun.to_csv('./Data/Future/June2017.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df_jul = get_data_API(2017,7,1,31)\n",
    "print len(df_jul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_jul.to_csv('./Data/Future/July2017.csv', encoding = 'utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
